{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.0\n",
      "Python version\n",
      "3.6.9 (default, Oct  8 2020, 12:12:24) \n",
      "[GCC 8.4.0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import sys\n",
    "print('Python version')\n",
    "print(sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "#from tensorflow.keras.preprocessing.image import load_img\n",
    "#from tensorflow.keras.preprocessing.image import img_to_array\n",
    "#from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = cifar100.load_data(label_mode=\"fine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (50000, 1), (10000, 32, 32, 3), (10000, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape, trainy.shape,testX.shape,testy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate out three classes out of 100\n",
    "def sep_class(trainx,trainy,y):\n",
    "    class_x=[]\n",
    "    for i in range(len(trainx)):\n",
    "        if trainy[i]==y:\n",
    "           #Normalise by 255\n",
    "            class_x.append(trainx[i]/255)\n",
    "        y_label=y*np.ones((len(class_x),1))\n",
    "    return (np.array(class_x),np.array(y_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1800, 32, 32, 3), (1800, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Separate out three classes out of 100   \n",
    "trainX0,trainy0=sep_class(trainX,trainy,0)\n",
    "testX0,testy0=sep_class(testX,testy,0)\n",
    "\n",
    "#Separate out one classes out of 100   \n",
    "trainX1,trainy1=sep_class(trainX,trainy,1)\n",
    "testX1,testy1=sep_class(testX,testy,1)\n",
    "\n",
    "#Separate out 2 class out of 100   \n",
    "trainX2,trainy2=sep_class(trainX,trainy,2)\n",
    "testX2,testy2=sep_class(testX,testy,2)\n",
    "\n",
    "# ----combining training and test data together---\n",
    "dataX=np.concatenate((trainX0,testX0,trainX1,testX1,trainX2,testX2)) # concatenating both train and test togther\n",
    "datay=np.concatenate((trainy0,testy0,trainy1,testy1,trainy2,testy2))\n",
    "\n",
    "# training samples\n",
    "dataXshuffle=list(zip(dataX,datay))\n",
    "np.random.shuffle(dataXshuffle)\n",
    "\n",
    "dataXn,datayn=zip(*dataXshuffle)\n",
    "dataXn=np.array(dataXn)\n",
    "datayn=np.array(datayn)\n",
    "dataXn.shape, datayn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1620, 32, 32, 3) (180, 32, 32, 3) (1620, 1) (180, 1)\n"
     ]
    }
   ],
   "source": [
    "#split data into training and test set\n",
    "trainX,testX,trainy,testy = train_test_split(dataXn,datayn,test_size=0.1,random_state=42)\n",
    "print(trainX.shape,testX.shape, trainy.shape, testy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainy=keras.utils.to_categorical(trainy,3)\n",
    "testy=keras.utils.to_categorical(testy,3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 3)  :  (1620, 3)\n"
     ]
    }
   ],
   "source": [
    "print(testy.shape, \" : \", trainy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_batched = tf.data.Dataset.from_tensor_slices((list(testX),list(testy))).batch(len(testy))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 32, 32, 3), (None, 3)), types: (tf.float64, tf.float32)>\n"
     ]
    }
   ],
   "source": [
    "print(test_batched)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_clients(image_list, label_list, num_clients=3, initial='clients'):\n",
    "    ''' return: a dictionary with keys clients' names and value as \n",
    "                data shards - tuple of images and label lists.\n",
    "        args: \n",
    "            image_list: a list of numpy arrays of training images\n",
    "            label_list:a list of binarized labels for each image\n",
    "            num_client: number of fedrated members (clients)\n",
    "            initials: the clients'name prefix, e.g, clients_1 \n",
    "            \n",
    "    '''\n",
    "\n",
    "    #create a list of client names\n",
    "    client_names = ['{}_{}'.format(initial, i+1) for i in range(num_clients)]\n",
    "\n",
    "    #randomize the data\n",
    "    data = list(zip(image_list, label_list))\n",
    "    np.random.shuffle(data)\n",
    "\n",
    "    #shard data and place at each client\n",
    "    size = len(data)//num_clients\n",
    "    shards = [data[i:i + size] for i in range(0, size*num_clients, size)]\n",
    "\n",
    "    #number of clients must equal number of shards\n",
    "    assert(len(shards) == len(client_names))\n",
    "    #clientN={'client_names[0]': shards[0]}\n",
    "    #return clientN\n",
    "    return {client_names[i] : shards[i] for i in range(len(client_names))} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['client_1', 'client_2', 'client_3'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create clients\n",
    "clients = create_clients(trainX,trainy, num_clients=3, initial='client')\n",
    "clients.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key: client_1 540\n",
      "key: client_2 540\n",
      "key: client_3 540\n"
     ]
    }
   ],
   "source": [
    "for key, value in clients.items():\n",
    "    print('key:',key,len(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_data(data_shard, bs=16):\n",
    "    '''Takes in a clients data shard and create a tfds object off it\n",
    "    args:\n",
    "        shard: a data, label constituting a client's data shard\n",
    "        bs:batch size\n",
    "    return:\n",
    "        tfds object'''\n",
    "    #seperate shard into data and labels lists\n",
    "    data, label = zip(*data_shard)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((list(data), list(label)))\n",
    "    return dataset.shuffle(len(label)).batch(bs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clients_batched = dict()\n",
    "for (client_name, data) in clients.items():\n",
    "    clients_batched[client_name] = batch_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('client_1', <BatchDataset shapes: ((None, 32, 32, 3), (None, 3)), types: (tf.float64, tf.float32)>), ('client_2', <BatchDataset shapes: ((None, 32, 32, 3), (None, 3)), types: (tf.float64, tf.float32)>), ('client_3', <BatchDataset shapes: ((None, 32, 32, 3), (None, 3)), types: (tf.float64, tf.float32)>)])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_batched.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None),\n",
       " TensorSpec(shape=(None, 3), dtype=tf.float32, name=None))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clients_batched['client_1'].element_spec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleKeras:\n",
    "    @staticmethod\n",
    "    def build(shape, classes):\n",
    "        model = Sequential()\n",
    "        #model._name = 'Name0_1'\n",
    "        model.add(Conv2D(16,kernel_size=(2,2),strides=(1,1),\n",
    "                    padding=\"same\", input_shape=(32,32,3),activation='relu',name='Conv1'))\n",
    "        model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),name='Pool1'))\n",
    "        model.add(Conv2D(32,kernel_size=(2,2),strides=(1,1),\n",
    "                    padding=\"same\", activation='relu',name='Conv2'))\n",
    "    \n",
    "        model.add(Flatten()) \n",
    "        model.add(Dense(250,activation='relu',name='Dense1'))\n",
    "        model.add(Dense(100, activation ='relu',name='Dense2')) # 3 classes\n",
    "        model.add(Dense(50, activation ='relu',name='Dense3'))  \n",
    "        model.add(Dense(3, activation ='softmax',name='Output'))\n",
    "        #model.compile(optimizer=Adam(lr=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "       # model.summary()    \n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def weight_scalling_factor(clients_trn_data, client_name):\n",
    "    client_names = list(clients_trn_data.keys())\n",
    "    #get the bs\n",
    "    bs = list(clients_trn_data[client_name])[0][0].shape[0]\n",
    "    #first calculate the total training data points across clinets\n",
    "    global_count = sum([tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy() for client_name in client_names])*bs\n",
    "    # get the total number of data points held by a client\n",
    "    local_count = tf.data.experimental.cardinality(clients_trn_data[client_name]).numpy()*bs\n",
    "    #print(global_count)\n",
    "    #print(local_count)\n",
    "    return local_count/global_count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def scale_model_weights(weight, scalar):\n",
    "    '''function for scaling a models weights'''\n",
    "    weight_final = []\n",
    "    steps = len(weight)\n",
    "    for i in range(steps):\n",
    "        weight_final.append(scalar * weight[i])\n",
    "    return weight_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sum_scaled_weights(scaled_weight_list):\n",
    "    '''Return the sum of the listed scaled weights. The is equivalent to scaled avg of the weights'''\n",
    "    avg_grad = list()\n",
    "    #get the average grad accross all client gradients\n",
    "    for grad_list_tuple in zip(*scaled_weight_list):\n",
    "        layer_mean = tf.math.reduce_sum(grad_list_tuple, axis=0)\n",
    "        avg_grad.append(layer_mean)\n",
    "    return avg_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(X_test, Y_test,  model, comm_round):\n",
    "    cce = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    #logits = model.predict(X_test, batch_size=100)\n",
    "    logits = model.predict(X_test)\n",
    "    loss = cce(Y_test, logits)\n",
    "    acc = accuracy_score(tf.argmax(logits, axis=1), tf.argmax(Y_test, axis=1))\n",
    "    print('comm_round: {} | global_acc: {:.3%} | global_loss: {}'.format(comm_round, acc, loss))\n",
    "    return acc, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 0 | global_acc: 66.111% | global_loss: 1.019399881362915\n"
     ]
    }
   ],
   "source": [
    "#initialize global model\n",
    "smlp_global = SimpleKeras()\n",
    "global_model = smlp_global.build((32,32,3),3)\n",
    "comms_round = 1\n",
    "modelList = {}\n",
    "#commence global training loop\n",
    "for comm_round in range(comms_round):\n",
    "            \n",
    "    # get the global model's weights - will serve as the initial weights for all local models\n",
    "    global_weights = global_model.get_weights()\n",
    "    #print(len(global_weights))\n",
    "    \n",
    "    #initial list to collect local model weights after scalling\n",
    "    scaled_local_weight_list = list()\n",
    "\n",
    "    #randomize client data - using keys\n",
    "    client_names= list(clients_batched.keys())\n",
    "    #print(client_names)\n",
    "    np.random.shuffle(client_names)\n",
    "    \n",
    "    #loop through each client and create new local model\n",
    "    for client in client_names:\n",
    "        smlp_local = SimpleKeras()\n",
    "        local_model = smlp_local.build((32,32,3),3)\n",
    "    \n",
    "        local_model.compile(loss='categorical_crossentropy', \n",
    "                      optimizer=Adam(lr=0.0001), \n",
    "                      metrics=['accuracy'])\n",
    "        \n",
    "        #set local model weight to the weight of the global model\n",
    "        local_model.set_weights(global_weights)\n",
    "        \n",
    "        #fit local model with client's data\n",
    "        local_model.fit(clients_batched[client], epochs=1, verbose=0)\n",
    "        #modelList.append(local_model)\n",
    "        modelList[client] = local_model\n",
    "        #scale the model weights and add to list\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(local_model.get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "        \n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "        \n",
    "    #to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "    average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "    \n",
    "    #update global model \n",
    "    global_model.set_weights(average_weights)\n",
    "\n",
    "    #test global model and print out metrics after each communications round\n",
    "    for(X_test, Y_test) in test_batched:\n",
    "        global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'client_1': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f35c1ab42b0>,\n",
       " 'client_2': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f35be2cfb38>,\n",
       " 'client_3': <tensorflow.python.keras.engine.sequential.Sequential at 0x7f35af7f02e8>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence of events for the paper\n",
    "- use 3 trained models as proposed models from clients\n",
    "- Utilize 3 peers with independent datasets to evaluate the proposed models\n",
    "- Choose 2 of the best proposed models\n",
    "- Aggregate the chosen models into the global model\n",
    "\n",
    "# Establish the datasets of the 3 peers\n",
    "- each peer is certified and trusted to work on the distributed system\n",
    "- each peer holds their own dataset and tests new submodels submitted to the system by clients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generate 3 client models (captured in modelList)\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "# Generate 3 independent Test data sets for the peers\n",
    "\n",
    "origTrainX,origTestX,origTrainy,origTesty = train_test_split(dataXn,datayn,test_size=0.1,random_state=42)\n",
    "\n",
    "o_trainy=keras.utils.to_categorical(origTrainy,3)\n",
    "o_testy=keras.utils.to_categorical(origTesty,3)\n",
    "\n",
    "## array_split divides the the array into the specified number of sarrays\n",
    "## this results in an array of arrays\n",
    "splitTestX = np.array_split(origTestX, 3)\n",
    "splitTestY = np.array_split(o_testy, 3)\n",
    "\n",
    "p_testX0 = splitTestX[0][:50]\n",
    "p_testy0 = splitTestY[0][:50]\n",
    " \n",
    "p_testX1 = splitTestX[1][:50]\n",
    "p_testy1 = splitTestY[1][:50]\n",
    "\n",
    "p_testX2 = splitTestX[2][:50]\n",
    "p_testy2 = splitTestY[2][:50]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Have the three peers test the proposed models and print the results\n",
    "- After the submodels are submitted they are stored in a shared drive accesible by the peers\n",
    "- The peers grab a copy of the model and then test its accuracy to their own datasets\n",
    "- The peers would then transact the results to the smart contract\n",
    "- This is done until all peers have scored the accuracy for the submodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 1 | global_acc: 46.000% | global_loss: 1.0169970989227295\n",
      "comm_round: 1 | global_acc: 68.000% | global_loss: 1.0148504972457886\n",
      "comm_round: 1 | global_acc: 62.000% | global_loss: 1.0343014001846313\n",
      "comm_round: 1 | global_acc: 44.000% | global_loss: 1.0258904695510864\n",
      "comm_round: 1 | global_acc: 62.000% | global_loss: 1.0054504871368408\n",
      "comm_round: 1 | global_acc: 70.000% | global_loss: 0.9993771314620972\n",
      "comm_round: 1 | global_acc: 64.000% | global_loss: 1.001991629600525\n",
      "comm_round: 1 | global_acc: 68.000% | global_loss: 1.0183180570602417\n",
      "comm_round: 1 | global_acc: 58.000% | global_loss: 1.028354287147522\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_1  :  0.5133333333333333\n",
      "client_2  :  0.66\n",
      "client_3  :  0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# Use peer models to report accuracy of the 2 client proposed models\n",
    "modelAvgs = {}\n",
    "\n",
    "peer0_acc = {}\n",
    "peer1_acc = {}\n",
    "peer2_acc = {}\n",
    "\n",
    "#peer0_acc = []\n",
    "#peer0_acc.append(test_model(p_testX0, p_testy0, modelList['client_1'], 1)[0])\n",
    "#peer0_acc.append(test_model(p_testX0, p_testy0, modelList['client_2'], 1)[0])\n",
    "#peer0_acc.append(test_model(p_testX0, p_testy0, modelList['client_3'], 1)[0])\n",
    "peer0_acc['client_1']=test_model(p_testX0, p_testy0, modelList['client_1'], 1)[0]\n",
    "peer0_acc['client_2']=test_model(p_testX0, p_testy0, modelList['client_2'], 1)[0]\n",
    "peer0_acc['client_3']=test_model(p_testX0, p_testy0, modelList['client_3'], 1)[0]\n",
    "\n",
    "#peer1_acc = []\n",
    "#peer1_acc.append(test_model(p_testX1, p_testy1, modelList['client_1'], 1)[0])\n",
    "#peer1_acc.append(test_model(p_testX1, p_testy1, modelList['client_2'], 1)[0])\n",
    "#peer1_acc.append(test_model(p_testX1, p_testy1, modelList['client_3'], 1)[0])\n",
    "peer1_acc['client_1']=test_model(p_testX1, p_testy1, modelList['client_1'], 1)[0]\n",
    "peer1_acc['client_2']=test_model(p_testX1, p_testy1, modelList['client_2'], 1)[0]\n",
    "peer1_acc['client_3']=test_model(p_testX1, p_testy1, modelList['client_3'], 1)[0]\n",
    "\n",
    "#peer2_acc = []\n",
    "#peer2_acc.append(test_model(p_testX2, p_testy2, modelList['client_1'], 1)[0])\n",
    "#peer2_acc.append(test_model(p_testX2, p_testy2, modelList['client_2'], 1)[0])\n",
    "#peer2_acc.append(test_model(p_testX2, p_testy2, modelList['client_3'], 1)[0])\n",
    "peer2_acc['client_1']=test_model(p_testX2, p_testy2, modelList['client_1'], 1)[0]\n",
    "peer2_acc['client_2']=test_model(p_testX2, p_testy2, modelList['client_2'], 1)[0]\n",
    "peer2_acc['client_3']=test_model(p_testX2, p_testy2, modelList['client_3'], 1)[0]\n",
    "\n",
    "# The smart contract will get the average and transact each peers result along with the average\n",
    "for client in modelList:\n",
    "    modelAvgs[client]=(peer0_acc[client]+peer1_acc[client]+peer2_acc[client])/3\n",
    "\n",
    "\n",
    "x = np.array([1,2,3])\n",
    "width = 0.1\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "peer0 = ax.bar(x-width, list(peer0_acc.values()), width, label='Peer0')\n",
    "peer1 = ax.bar(x, list(peer1_acc.values()), width, label='Peer1')\n",
    "peer2 = ax.bar(x+width, list(peer2_acc.values()), width, label='Peer2')\n",
    "\n",
    "def autolabel(rects):\n",
    "    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "autolabel(peer0)\n",
    "autolabel(peer1)\n",
    "autolabel(peer2)\n",
    "        \n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i in modelAvgs:\n",
    "    print(i, \" : \", modelAvgs[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the best models and aggregate them into the global model\n",
    "- In this example the top 2 out of three are chosen and then aggregated\n",
    "- The top models should be chosen based on the criteria specified in the paper\n",
    "- The top models are then combined/aggregated by a chosen peer\n",
    "- A hash of the model and its accuracy are transacted to the global model blockchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 2 ranked models   :  [0.66, 0.6333333333333333]\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# Combine client models into global model\n",
    "global_model = smlp_global.build((32,32,3),3)\n",
    "comms_round = 1\n",
    "\n",
    "top2 = sorted(modelAvgs.values(), reverse=True)[:2]\n",
    "print(\"Top 2 ranked models \", \" : \", top2)\n",
    "\n",
    "for client in modelList:    \n",
    "    if modelAvgs[client] in top2:\n",
    "        scaling_factor = weight_scalling_factor(clients_batched, client)\n",
    "        scaled_weights = scale_model_weights(modelList[client].get_weights(), scaling_factor)\n",
    "        scaled_local_weight_list.append(scaled_weights)\n",
    "\n",
    "        #clear session to free memory after each communication round\n",
    "        K.clear_session()\n",
    "\n",
    "#to get the average over all the local model, we simply take the sum of the scaled weights\n",
    "average_weights = sum_scaled_weights(scaled_local_weight_list)\n",
    "\n",
    "#update global model \n",
    "global_model.set_weights(average_weights)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comm_round: 0 | global_acc: 69.444% | global_loss: 0.8578529953956604\n"
     ]
    }
   ],
   "source": [
    "#--------------------------------------------------------------------\n",
    "# Report global model accuracy\n",
    "\n",
    "#test global model and print out metrics after each communications round\n",
    "for(X_test, Y_test) in test_batched:\n",
    "    global_acc, global_loss = test_model(X_test, Y_test, global_model, comm_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "50\n",
      "WARNING:tensorflow:From /home/pfoytik/.local/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: fed1_recognition.model/assets\n",
      "comm_round: 1 | global_acc: 62.000% | global_loss: 1.0054504871368408\n",
      "(0.62, <tf.Tensor: shape=(), dtype=float32, numpy=1.0054505>)\n"
     ]
    }
   ],
   "source": [
    "#test_model(p_testX1, p_testy1, modelList['client_1'], 1)[0]\n",
    "\n",
    "## Handle training data load/save\n",
    "np.save('testX2.npy', p_testX1, allow_pickle=True)\n",
    "X0 = np.load('testX2.npy', allow_pickle=True)\n",
    "\n",
    "np.save('testy2.npy', p_testy1, allow_pickle=True)\n",
    "y0 = np.load('testy2.npy', allow_pickle=True)\n",
    "\n",
    "print(len(X0))\n",
    "print(len(y0))\n",
    "\n",
    "## Handling model load/model save\n",
    "modelList['client_1'].save('fed1_recognition.model')\n",
    "print(test_model(X0, y0, modelList['client_2'], 1))\n",
    "#client1 = model = tf.keras.models.load_model('fed1_recognition.model')\n",
    "#print(client1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
